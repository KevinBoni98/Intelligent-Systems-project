{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23654efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# üß© Convert YOLO + CSV Datasets into Pandas DataFrames (no saving)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# %%\n",
    "# üìò 1. Load YOLO config\n",
    "\n",
    "yaml_path = \"datasets/Playing-Cards-Object-Detection-main/data.yaml\"\n",
    "with open(yaml_path, \"r\") as f:\n",
    "    yolo_cfg = yaml.safe_load(f)\n",
    "\n",
    "yolo_class_names = yolo_cfg[\"names\"]\n",
    "yolo_class_to_id = {name: idx for idx, name in enumerate(yolo_class_names)}\n",
    "\n",
    "print(f\"Loaded {len(yolo_class_names)} classes from {yaml_path}\")\n",
    "\n",
    "# %%\n",
    "# üß© Helpers\n",
    "\n",
    "IMG_EXTS = [\".jpg\", \".jpeg\", \".png\"]\n",
    "\n",
    "def find_image(images_dir: Path, stem: str) -> Path | None:\n",
    "    \"\"\"Return the first existing image path among common extensions.\"\"\"\n",
    "    for ext in IMG_EXTS:\n",
    "        p = images_dir / f\"{stem}{ext}\"\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def get_image_size(filename, base_folder):\n",
    "    path = Path(base_folder) / filename\n",
    "    with Image.open(path) as im:\n",
    "        return im.width, im.height\n",
    "# %%\n",
    "# üìò 2. Parse YOLO label files into a DataFrame (using actual structure)\n",
    "\n",
    "def load_yolo_split(base_dir: Path) -> pd.DataFrame:\n",
    "    labels_dir = base_dir / \"labels\"\n",
    "    images_dir = base_dir / \"images\"\n",
    "\n",
    "    if not labels_dir.exists():\n",
    "        print(f\"‚ö†Ô∏è No labels folder found: {labels_dir}\")\n",
    "        return pd.DataFrame(columns=[\"image\", \"class_id\", \"class_name\", \"bbox_x_center\", \"bbox_y_center\", \"bbox_width\", \"bbox_height\", \"image_width\", \"image_height\"])\n",
    "\n",
    "    txt_files = sorted(labels_dir.glob(\"*.txt\"))\n",
    "    if not txt_files:\n",
    "        print(f\"‚ö†Ô∏è No label files found in {labels_dir}\")\n",
    "        return pd.DataFrame(columns=[\"image\", \"class_id\", \"class_name\", \"bbox_x_center\", \"bbox_y_center\", \"bbox_width\", \"bbox_height\", \"image_width\", \"image_height\"])\n",
    "\n",
    "    all_rows = []\n",
    "    for txt_file in txt_files:\n",
    "        stem = txt_file.stem\n",
    "        image_path = find_image(images_dir, stem)\n",
    "        image_str = str(image_path) if image_path else str(images_dir / f\"{stem}.jpg\")\n",
    "        image_width, image_height = get_image_size( f\"{stem}.jpg\",images_dir)\n",
    "\n",
    "        with open(txt_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                class_id, x_center, y_center, width, height = parts\n",
    "                class_id = int(class_id)\n",
    "                if class_id >= len(yolo_class_names):\n",
    "                    continue\n",
    "                class_name = yolo_class_names[class_id]\n",
    "                all_rows.append(\n",
    "                    [image_str, class_id, class_name, float(x_center), float(y_center), float(width), float(height), float(image_width), float(image_height)]\n",
    "                )\n",
    "    df = pd.DataFrame(all_rows, columns=[\"image\", \"class_id\", \"class_name\", \"bbox_x_center\", \"bbox_y_center\", \"bbox_width\", \"bbox_height\", \"image_width\", \"image_height\"])\n",
    "    return df\n",
    "\n",
    "# Real dataset paths\n",
    "base_path = Path(\"datasets/Playing-Cards-Object-Detection-main\")\n",
    "train_base = base_path / \"train\"\n",
    "valid_base = base_path / \"valid\"\n",
    "test_base  = base_path / \"test\"\n",
    "\n",
    "yolo_train_df = load_yolo_split(train_base)\n",
    "yolo_valid_df = load_yolo_split(valid_base)\n",
    "yolo_test_df  = load_yolo_split(test_base)\n",
    "\n",
    "print(f\"YOLO train: {len(yolo_train_df)}  |  valid: {len(yolo_valid_df)}  |  test: {len(yolo_test_df)}\")\n",
    "\n",
    "# %%\n",
    "# üß† 3. Mapping from full names ‚Üí YOLO short names\n",
    "\n",
    "full_to_short = {\n",
    "    \"ace of clubs\": \"Ac\", \"ace of diamonds\": \"Ad\", \"ace of hearts\": \"Ah\", \"ace of spades\": \"As\",\n",
    "    \"two of clubs\": \"2c\", \"two of diamonds\": \"2d\", \"two of hearts\": \"2h\", \"two of spades\": \"2s\",\n",
    "    \"three of clubs\": \"3c\", \"three of diamonds\": \"3d\", \"three of hearts\": \"3h\", \"three of spades\": \"3s\",\n",
    "    \"four of clubs\": \"4c\", \"four of diamonds\": \"4d\", \"four of hearts\": \"4h\", \"four of spades\": \"4s\",\n",
    "    \"five of clubs\": \"5c\", \"five of diamonds\": \"5d\", \"five of hearts\": \"5h\", \"five of spades\": \"5s\",\n",
    "    \"six of clubs\": \"6c\", \"six of diamonds\": \"6d\", \"six of hearts\": \"6h\", \"six of spades\": \"6s\",\n",
    "    \"seven of clubs\": \"7c\", \"seven of diamonds\": \"7d\", \"seven of hearts\": \"7h\", \"seven of spades\": \"7s\",\n",
    "    \"eight of clubs\": \"8c\", \"eight of diamonds\": \"8d\", \"eight of hearts\": \"8h\", \"eight of spades\": \"8s\",\n",
    "    \"nine of clubs\": \"9c\", \"nine of diamonds\": \"9d\", \"nine of hearts\": \"9h\", \"nine of spades\": \"9s\",\n",
    "    \"ten of clubs\": \"10c\", \"ten of diamonds\": \"10d\", \"ten of hearts\": \"10h\", \"ten of spades\": \"10s\",\n",
    "    \"jack of clubs\": \"Jc\", \"jack of diamonds\": \"Jd\", \"jack of hearts\": \"Jh\", \"jack of spades\": \"Js\",\n",
    "    \"queen of clubs\": \"Qc\", \"queen of diamonds\": \"Qd\", \"queen of hearts\": \"Qh\", \"queen of spades\": \"Qs\",\n",
    "    \"king of clubs\": \"Kc\", \"king of diamonds\": \"Kd\", \"king of hearts\": \"Kh\", \"king of spades\": \"Ks\",\n",
    "}\n",
    "\n",
    "typo_fixes = {\"eigth\": \"eight\"}\n",
    "SUIT_BY_PREFIX = {\"c\": \"clubs\", \"d\": \"diamonds\", \"h\": \"hearts\", \"s\": \"spades\"}\n",
    "\n",
    "def normalize_full_name(s: str) -> str:\n",
    "    s = s.strip().lower()\n",
    "    for bad, good in typo_fixes.items():\n",
    "        s = s.replace(bad, good)\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def repair_label(label: str, filename: str) -> str | None:\n",
    "    if label == \"seven of seven\":\n",
    "        prefix = Path(filename).stem[0].lower()\n",
    "        suit = SUIT_BY_PREFIX.get(prefix)\n",
    "        if suit:\n",
    "            return f\"seven of {suit}\"\n",
    "    return None\n",
    "\n",
    "def map_full_to_short(label: str, filename: str) -> str | None:\n",
    "    norm = normalize_full_name(label)\n",
    "    if norm in full_to_short:\n",
    "        return full_to_short[norm]\n",
    "    repaired = repair_label(norm, filename)\n",
    "    if repaired in full_to_short:\n",
    "        return full_to_short[repaired]\n",
    "    return None\n",
    "\n",
    "# %%\n",
    "# üìò 4. Parse VOC CSVs and convert to YOLO format\n",
    "\n",
    "def convert_voc_to_yolo(xmin, ymin, xmax, ymax, img_w, img_h):\n",
    "    x_center = (xmin + xmax) / 2 / img_w\n",
    "    y_center = (ymin + ymax) / 2 / img_h\n",
    "    width = (xmax - xmin) / img_w\n",
    "    height = (ymax - ymin) / img_h\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "def parse_voc_csv(csv_path: str, base_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse VOC-style CSV and convert to YOLO format.\n",
    "    Adds full image path based on the dataset base directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_csv = pd.read_csv(csv_path)\n",
    "    all_rows = []\n",
    "    skipped = 0\n",
    "\n",
    "    for _, row in df_csv.iterrows():\n",
    "        fname = str(row[\"filename\"]).strip()\n",
    "        label = str(row[\"class\"]).strip()\n",
    "\n",
    "        mapped = map_full_to_short(label, fname)\n",
    "        if not mapped:\n",
    "            print(f\"‚ö†Ô∏è Skipping unknown class: '{label}' in {fname}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img_w = float(row[\"width\"])\n",
    "            img_h = float(row[\"height\"])\n",
    "            if img_w == 0 or img_h == 0:\n",
    "                print(f\"‚ö†Ô∏è Skipping {fname}: image size is zero ({img_w}x{img_h})\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping {fname}: bad width/height ({e})\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        x_center, y_center, width, height = convert_voc_to_yolo(\n",
    "            float(row[\"xmin\"]), float(row[\"ymin\"]),\n",
    "            float(row[\"xmax\"]), float(row[\"ymax\"]),\n",
    "            img_w, img_h\n",
    "        )\n",
    "\n",
    "        class_id = yolo_class_to_id[mapped]\n",
    "        image_path = str(Path(base_dir) / fname)\n",
    "\n",
    "        all_rows.append([image_path, class_id, mapped, x_center, y_center, width, height, img_w, img_h])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        all_rows,\n",
    "        columns=[\"image\", \"class_id\", \"class_name\", \"bbox_x_center\", \"bbox_y_center\", \"bbox_width\", \"bbox_height\", \"image_width\", \"image_height\"]\n",
    "    )\n",
    "    print(f\"{csv_path}: parsed {len(df)} valid annotations, skipped {skipped}.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "voc_train_csv = \"datasets/Playing-Cards-Images-Object-Detection-Dataset/train_labels.csv\"\n",
    "voc_test_csv  = \"datasets/Playing-Cards-Images-Object-Detection-Dataset/test_labels.csv\"\n",
    "\n",
    "voc_train_base = \"datasets/Playing-Cards-Images-Object-Detection-Dataset/train/train\"\n",
    "voc_test_base  = \"datasets/Playing-Cards-Images-Object-Detection-Dataset/test/test\"\n",
    "\n",
    "voc_train_df = parse_voc_csv(voc_train_csv, voc_train_base)\n",
    "voc_test_df  = parse_voc_csv(voc_test_csv, voc_test_base)\n",
    "\n",
    "voc_df = pd.concat([voc_train_df, voc_test_df], ignore_index=True)\n",
    "print(f\"VOC total (CSV): {len(voc_df)} annotations\")\n",
    "\n",
    "# %%\n",
    "# ‚úÖ 5. Final Output\n",
    "\n",
    "print(\"YOLO (train):\")\n",
    "display(yolo_train_df.head())\n",
    "\n",
    "print(\"YOLO (valid):\")\n",
    "display(yolo_valid_df.head())\n",
    "\n",
    "print(\"YOLO (test):\")\n",
    "display(yolo_test_df.head())\n",
    "\n",
    "print(\"VOC (train):\")\n",
    "display(voc_train_df.head())\n",
    "\n",
    "print(\"VOC (test):\")\n",
    "display(voc_test_df.head())\n",
    "\n",
    "# 6. Save to CSV\n",
    "yolo_train_df.to_csv(\"datasets/Playing-Cards-Object-Detection-main/yolo_train_converted.csv\", index=False)\n",
    "yolo_valid_df.to_csv(\"datasets/Playing-Cards-Object-Detection-main/yolo_valid_converted.csv\", index=False)\n",
    "yolo_test_df.to_csv(\"datasets/Playing-Cards-Object-Detection-main/yolo_test_converted.csv\", index=False)\n",
    "yolo_all_df = pd.concat([yolo_train_df, yolo_valid_df, yolo_test_df], ignore_index=True)\n",
    "yolo_all_df.to_csv(\"datasets/Playing-Cards-Object-Detection-main/yolo_all_converted.csv\", index=False)\n",
    "voc_train_df.to_csv(\"datasets/Playing-Cards-Images-Object-Detection-Dataset/voc_train_converted.csv\", index=False)\n",
    "voc_test_df.to_csv(\"datasets/Playing-Cards-Images-Object-Detection-Dataset/voc_test_converted.csv\", index=False)\n",
    "voc_df.to_csv(\"datasets/Playing-Cards-Images-Object-Detection-Dataset/voc_all_converted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc86d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/Playing-Cards-Labelized-Dataset/train_cards_label.csv: parsed 40089 valid annotations, skipped 0.\n",
      "datasets/Playing-Cards-Labelized-Dataset/test_cards_label.csv: parsed 8004 valid annotations, skipped 0.\n",
      "Labelized total: 48093 annotations\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# üìò 5. Parse Labelized CSVs (Already in short class format, like \"Qc\", \"9s\", \"2h\")\n",
    "\n",
    "def parse_labelized_csv(csv_path: str, base_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse the Labelized CSV dataset where class names are already short (e.g. 'Qc', '9s').\n",
    "    Converts VOC-style bounding boxes to YOLO format and returns a DataFrame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"‚ö†Ô∏è Missing file: {csv_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_csv = pd.read_csv(csv_path)\n",
    "    all_rows = []\n",
    "    skipped = 0\n",
    "\n",
    "    for _, row in df_csv.iterrows():\n",
    "        fname = str(row[\"filename\"]).strip()\n",
    "        label = str(row[\"class\"]).strip()\n",
    "\n",
    "        if label not in yolo_class_to_id:\n",
    "            print(f\"‚ö†Ô∏è Skipping unknown class '{label}' in {fname}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img_w = float(row[\"width\"])\n",
    "            img_h = float(row[\"height\"])\n",
    "            if img_w == 0 or img_h == 0:\n",
    "                print(f\"‚ö†Ô∏è Skipping {fname}: invalid size ({img_w}x{img_h})\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping {fname}: error reading width/height ({e})\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        x_center, y_center, width, height = convert_voc_to_yolo(\n",
    "            float(row[\"xmin\"]), float(row[\"ymin\"]),\n",
    "            float(row[\"xmax\"]), float(row[\"ymax\"]),\n",
    "            img_w, img_h\n",
    "        )\n",
    "\n",
    "        class_id = yolo_class_to_id[label]\n",
    "        image_path = str(Path(base_dir) / fname)\n",
    "\n",
    "        all_rows.append([image_path, class_id, label, x_center, y_center, width, height, img_w, img_h])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        all_rows,\n",
    "        columns=[\"image\", \"class_id\", \"class_name\", \"bbox_x_center\", \"bbox_y_center\", \"bbox_width\", \"bbox_height\", \"image_width\", \"image_height\"]\n",
    "    )\n",
    "\n",
    "    print(f\"{csv_path}: parsed {len(df)} valid annotations, skipped {skipped}.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Paths\n",
    "labelized_train_csv = \"datasets/Playing-Cards-Labelized-Dataset/train_cards_label.csv\"\n",
    "labelized_test_csv  = \"datasets/Playing-Cards-Labelized-Dataset/test_cards_label.csv\"\n",
    "\n",
    "labelized_train_base = \"datasets/Playing-Cards-Labelized-Dataset/train\"\n",
    "labelized_test_base  = \"datasets/Playing-Cards-Labelized-Dataset/test\"\n",
    "\n",
    "# Load\n",
    "labelized_train_df = parse_labelized_csv(labelized_train_csv, labelized_train_base)\n",
    "labelized_test_df  = parse_labelized_csv(labelized_test_csv, labelized_test_base)\n",
    "\n",
    "labelized_df = pd.concat([labelized_train_df, labelized_test_df], ignore_index=True)\n",
    "print(f\"Labelized total: {len(labelized_df)} annotations\")\n",
    "\n",
    "# Save\n",
    "labelized_train_df.to_csv(\"datasets/Playing-Cards-Labelized-Dataset/labelized_train_converted.csv\", index=False)\n",
    "labelized_test_df.to_csv(\"datasets/Playing-Cards-Labelized-Dataset/labelized_test_converted.csv\", index=False)\n",
    "labelized_df.to_csv(\"datasets/Playing-Cards-Labelized-Dataset/labelized_all_converted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03d664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Could not infer class from JOKER0.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER1.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER10.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER11.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER12.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER13.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER14.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER15.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER16.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER17.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER18.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER19.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER2.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER20.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER21.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER22.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER23.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER24.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER25.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER26.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER27.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER28.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER29.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER3.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER30.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER31.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER32.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER33.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER34.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER35.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER36.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER37.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER38.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER39.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER4.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER40.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER41.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER42.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER43.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER44.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER45.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER46.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER47.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER48.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER49.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER5.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER50.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER6.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER7.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER8.txt\n",
      "‚ö†Ô∏è Could not infer class from JOKER9.txt\n",
      "‚úÖ Parsed 2707 annotations from datasets/The-Complete-Playing-Card-Dataset/YOLO_Annotations/YOLO_Annotations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>bbox_x_center</th>\n",
       "      <th>bbox_y_center</th>\n",
       "      <th>bbox_width</th>\n",
       "      <th>bbox_height</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/The-Complete-Playing-Card-Dataset/Ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>10c</td>\n",
       "      <td>0.325087</td>\n",
       "      <td>0.665365</td>\n",
       "      <td>0.083767</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>3456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/The-Complete-Playing-Card-Dataset/Ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>10c</td>\n",
       "      <td>0.326280</td>\n",
       "      <td>0.623698</td>\n",
       "      <td>0.073134</td>\n",
       "      <td>0.069734</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>3456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/The-Complete-Playing-Card-Dataset/Ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>10c</td>\n",
       "      <td>0.559462</td>\n",
       "      <td>0.498264</td>\n",
       "      <td>0.092448</td>\n",
       "      <td>0.063079</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>3456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/The-Complete-Playing-Card-Dataset/Ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>10c</td>\n",
       "      <td>0.513997</td>\n",
       "      <td>0.449508</td>\n",
       "      <td>0.051432</td>\n",
       "      <td>0.068576</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>3456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/The-Complete-Playing-Card-Dataset/Ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>10c</td>\n",
       "      <td>0.307834</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.055339</td>\n",
       "      <td>0.079282</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>3456.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  class_id class_name  \\\n",
       "0  datasets/The-Complete-Playing-Card-Dataset/Ima...         0        10c   \n",
       "1  datasets/The-Complete-Playing-Card-Dataset/Ima...         0        10c   \n",
       "2  datasets/The-Complete-Playing-Card-Dataset/Ima...         0        10c   \n",
       "3  datasets/The-Complete-Playing-Card-Dataset/Ima...         0        10c   \n",
       "4  datasets/The-Complete-Playing-Card-Dataset/Ima...         0        10c   \n",
       "\n",
       "   bbox_x_center  bbox_y_center  bbox_width  bbox_height  image_width  \\\n",
       "0       0.325087       0.665365    0.083767     0.039641       4608.0   \n",
       "1       0.326280       0.623698    0.073134     0.069734       4608.0   \n",
       "2       0.559462       0.498264    0.092448     0.063079       4608.0   \n",
       "3       0.513997       0.449508    0.051432     0.068576       4608.0   \n",
       "4       0.307834       0.513889    0.055339     0.079282       4608.0   \n",
       "\n",
       "   image_height  \n",
       "0        3456.0  \n",
       "1        3456.0  \n",
       "2        3456.0  \n",
       "3        3456.0  \n",
       "4        3456.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# üìò 6. Parse \"The-Complete-Playing-Card-Dataset\" (YOLO format, with only .txt and images)\n",
    "\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "COMPLETE_CLASSES = [\n",
    "    '10c', '10d', '10h', '10s',\n",
    "    '2c', '2d', '2h', '2s',\n",
    "    '3c', '3d', '3h', '3s',\n",
    "    '4c', '4d', '4h', '4s',\n",
    "    '5c', '5d', '5h', '5s',\n",
    "    '6c', '6d', '6h', '6s',\n",
    "    '7c', '7d', '7h', '7s',\n",
    "    '8c', '8d', '8h', '8s',\n",
    "    '9c', '9d', '9h', '9s',\n",
    "    'Ac', 'Ad', 'Ah', 'As',\n",
    "    'Jc', 'Jd', 'Jh', 'Js',\n",
    "    'Kc', 'Kd', 'Kh', 'Ks',\n",
    "    'Qc', 'Qd', 'Qh', 'Qs'\n",
    "]\n",
    "COMPLETE_CLASS_TO_ID = {name.lower(): idx for idx, name in enumerate(COMPLETE_CLASSES)}\n",
    "\n",
    "def parse_complete_yolo_dataset(base_dir: str) -> pd.DataFrame:\n",
    "    base_dir = Path(base_dir)\n",
    "    labels_dir = base_dir / \"YOLO_Annotations\" / \"YOLO_Annotations\"\n",
    "    images_dir = base_dir / \"Images\" / \"Images\"\n",
    "\n",
    "    if not labels_dir.exists():\n",
    "        print(f\"‚ö†Ô∏è Labels folder not found: {labels_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_rows = []\n",
    "    txt_files = sorted(labels_dir.glob(\"*.txt\"))\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        stem = txt_file.stem  # e.g. \"10C15\", \"AC12\"\n",
    "        match = re.match(r\"([0-9]{1,2}[cdhsCDHS]|[AJQKajqk][cdhsCDHS])\", stem)\n",
    "        if not match:\n",
    "            print(f\"‚ö†Ô∏è Could not infer class from {txt_file.name}\")\n",
    "            continue\n",
    "\n",
    "        class_name = match.group(1).lower()\n",
    "        if class_name not in COMPLETE_CLASS_TO_ID:\n",
    "            print(f\"‚ö†Ô∏è Unknown class '{class_name}' in {txt_file.name}\")\n",
    "            continue\n",
    "\n",
    "        class_id = COMPLETE_CLASS_TO_ID[class_name]\n",
    "        image_path = find_image(images_dir, stem)\n",
    "        if not image_path:\n",
    "            print(f\"‚ö†Ô∏è Missing image for {stem}\")\n",
    "            continue\n",
    "\n",
    "        with Image.open(image_path) as im:\n",
    "            img_w, img_h = im.width, im.height\n",
    "\n",
    "        with open(txt_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                _, x_center, y_center, width, height = parts\n",
    "                all_rows.append([\n",
    "                    str(image_path), class_id, class_name,\n",
    "                    float(x_center), float(y_center), float(width), float(height),\n",
    "                    float(img_w), float(img_h)\n",
    "                ])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        all_rows,\n",
    "        columns=[\n",
    "            \"image\", \"class_id\", \"class_name\",\n",
    "            \"bbox_x_center\", \"bbox_y_center\",\n",
    "            \"bbox_width\", \"bbox_height\",\n",
    "            \"image_width\", \"image_height\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Parsed {len(df)} annotations from {labels_dir}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Esegui la conversione\n",
    "complete_base = \"datasets/The-Complete-Playing-Card-Dataset\"\n",
    "complete_df = parse_complete_yolo_dataset(complete_base)\n",
    "\n",
    "# Salva il CSV risultante\n",
    "complete_df.to_csv(\"datasets/The-Complete-Playing-Card-Dataset/complete_converted.csv\", index=False)\n",
    "\n",
    "# Mostra un‚Äôanteprima\n",
    "display(complete_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
